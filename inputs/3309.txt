I'm teaching a TEI class this weekend, so I've been pondering it a bit.  I've come to the conclusion that calling what we do with TEI "text encoding" is misleading.  I think what we're really doing is text modeling.TEI provides an XML vocabulary that lets you produce models of texts that can be used for a variety of purposes. Not a Model of Text, mind you, but models (lowercase) of texts (also lowercase).  TEI has made the (interesting, significant) decision to piggyback its semantics on the structure of XML, which is tree-based.  So XML structure implies semantics for a lot of TEI.  For example, paragraph text appears inside <p> tags; to mark a personal name, I surround the name with a <persname> tag, and so on.  This arrangement is extremely convenient for processing purposes: it is trivial to transform the TEI <p> into an HTML <p>*, for example, or the <persname> into an HTML hyperlink, which points to more information about the person.  It means, however, that TEI's modeling capabilities are to a large extent XML's own.  This approach has opened TEI up to criticism.  Buzetti (2002) has argued that its tree structure simply isn't expressive enough to represent the complexities of text, and Schmidt (2010) criticizes TEI for (among other problems) being a bad model of text, because it imposes editorial interpretation on the text itself.  The main disagreement I have with Schmidt's argument is the assumption that there is a text independent of the editorial apparatus.  Maybe there is sometimes, but I can point at many examples where there is no text, as such, only readings.  And a reading is, must be, an interpretive exercise.  So I'd argue that TEI is at least honest in that it puts the editorial interventions front and center where they are obvious.As for the argument that TEI's structure is inadequate to model certain aspects of text, I can only agree.  But TEI has proved good enough to do a lot of serious scholarly work.  That, and the fact that its choice of structure means it can bring powerful XML tools to bear on the problems it confronts, means that TEI represents a "worse is better" solution.â   It works a lot of the time, doesn't claim to be perfect, and incrementally improves.  Where TEI isn't adequate to model a text in the way you want to use it, then you either shouldn't use it, or should figure out how to extend it.One should bear in mind that any digital representation of a text is ipso facto a model.  It's impossible do anything digital without a model (whether you realize it's there or not).  Even if you're just transcribing text from a printed page to a text editor you're making editorial decisions, like what character encoding to use, how to represent typographic features in that encoding, how to represent whitespace, and what to do with things you can't easily type (inline figures or symbols without a Unicode representation, for example).So why argue that TEI is a language for modeling texts, rather than a language for "encoding" texts?  The simple answer is that this is a better way of explaining what people use TEI for.  TEI provides a lot of tags to choose from.  No-one uses them all.  Some are arguably incompatible with one another.  We tag the things in a text that we care about and want to use.  In other words, we build models of the source text, models that reflect what we think is going on structurally, semantically, or linguistically in the text, and/or models that we hope to exploit in some way. For example, EpiDoc is designed to produce critical editions of inscribed or handwritten ancient texts.  It is concerned with producing an edition (a reading) of the source text that records the editor's observations of and ideas about that text.  It does not at this point concern itself with marking personal or geographic names in the text.  An EpiDoc document is a particular model of the text that focuses on the editor's reading of that text.  As a counterexample, I might want to use TEI to produce a graph of the interactions of characters in Hamlet.  If I wanted to do that, I would produce a TEI document that marked people and whom they were addressing when they spoke.  This would be a completely different model of the text than a critical edition of Hamlet might be.  I could even try to do both at the same time, but that might be a messâmodels are easier to deal with when they focus on one thing.This way of understanding TEI makes clear a problem that arises whenever one tries to merge collections of TEI documents: that of compatibility.  Just because two documents are marked up in TEI, that does not mean they are interoperable.  This is because each document represents the editor's model of that text.  Compatibility is certainly achievable if both documents follow the same set of conventions, but we shouldn't expect it any more than we'd expect to be able to merge any two models that follow different ground rules.Notes* with the caveat that the semantics of TEI <p> and HTML <p> are different, and there may be problems. TEI's <p> can contain lists, for example, whereas HTML's cannot.â  See http://www.dreamsongs.com/RiseOfWorseIsBetter.htmlYes, I wrote a blog post with endnotes and bibliography. Sue me.Buzzetti D. "Digital Representation and the Text Model." New Literary History 2002; 33.1:61-88.Schmidt, D. "The Inadequacy of Embedded Markup for Cultural Heritage Texts." Literary and LInguistic Computing 2010; 25.3:337-356.
