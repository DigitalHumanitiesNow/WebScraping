 I publishedÂ a blog postÂ with the sameÂ title a good while back.Â Here’s what I wrote at the time: Citizen-based, crowdsourced election observation initiatives are on the rise. Leading election monitoring organizations are also looking to leverage citizen-based reporting to complement their own professional election monitoring efforts. Meanwhile, the information revolution continues apace, with the number of new mobile phone subscriptions up by over 1 billion in just the past 36 months alone. The volume of election-related reports generated by âthe crowdâ is thus expected to grow significantly in the coming years. But international, national and local election monitoring organizations are completely unprepared to deal with the rise of Big (Election) Data. I thusÂ introduced a new project to “develop a free and open source platform to automatically filter relevant election reports from the crowd.” I’m pleasedÂ to report that my team and I at QCRIÂ have just tested AIME during an actual electionÂ for the very first timeâthe 2015 Nigerian Elections. My QCRI Research AssistantÂ PeterÂ Mosur (co-author of this blog post) collaborated directly with Oludotun Babayemi from Clonehouse Nigeria and Chuks Ojidoh from the Community Life Project &Â Reclaim Naija to deploy and test the AIME platform. AIME is a free andÂ open source (experimental) solutionÂ that combines crowd-sourcingÂ with Artificial Intelligence to automatically identify tweets of interest during major elections. As organizationsÂ engaged in election monitoring well know,Â thereÂ can be a lotÂ chatter on social media as people rallyÂ behind their chosen candidates, announce this to the world, ask their friends and family who they will be voting for, and updating others when they have voted while posting aboutÂ election related incidents they may have witnessed. This can make it ratherÂ challenging to findÂ reports relevant to electionÂ monitoring groups.  Election monitors typically monitor instancesÂ of violence, election rigging, and voter issues. These incidentsÂ are monitored because they revealÂ problems that arise with the elections. Election monitoring initiatives such as Reclaim Naija & Uzabe also monitor several other type ofÂ incidents butÂ for the purposes of testing the AIME platform, we selected three types of events mentioned above. In order to automatically identify tweets related to these events, oneÂ must firstÂ provide AIME with example tweets. (Of course, if there is no Twitter traffic to begin with, then there won’t be much need for AIME, which isÂ precisely why we developed an SMS extensionÂ that can be used with AIME). So where doesÂ the crowdsourcing comes in? Users of AIME can ask the crowd to tag tweets related to election-violence, rigging and voter issues by simplyÂ clicking on tagging tweetsÂ posted to the AIME platform with the appropriate eventÂ type. (Several quality control mechanisms are built in to ensure data quality. Also, one does not need to use crowdsourcing to tag the tweets; this can be done internally as well or instead). What AIME does next is useÂ a technique fromÂ Artificial Intelligence (AI) called statistical machine learning to understand patterns in the human-tagged tweets. In other words, it begins to recognize which tweets belong inÂ which category typeâviolence, rigging and voter issues. AIME will then auto-classify newÂ tweets that areÂ related to these categoriesÂ (and can auto-classify around 2 millions tweets or text messages perÂ minute).  Before creating ourÂ automatic classifier for the Nigerian Elections, we first needed toÂ collect examples of tweets related to election violence, rigging and voter issues in orderÂ to teach AIME.Â Oludotun Babayemi and Chuks Ojidoh kindlyÂ provided the expert local knowledge needed to identify the keywords we should be following on Twitter (using AIME). They graciously gave usÂ many different keywords to use as well as a list of trusted Twitter accounts to follow for election-related messages. (Due to difficulties with AIME, we were not able to use the trusted accounts. In addition, many of the suggested keywords were unusable since wordsÂ likeÂ âaggressiveâ, âdetonateâ, and âsecurityâ would have resulted in large amount of false positives). Here is theÂ full list of keywords used by AIME: Nigeria elections, nigeriadecides, Nigeria decides, INEC, GEJ, Change Nigeria, Nigeria Transformation, President Jonathan, Goodluck Jonathan, Sai Buhari, saibuhari, All progressives congress, Osibanjo, Sambo, Peoples Democratic Party, boko haram, boko, area boys, nigeria2015, votenotfight, GEJwinsit, iwillvoteapc, gmb2015, revoda, thingsmustchange, Â and march4buhari Â Â  Out of this list, âNigeriaDecidesâ was by far the most popular keyword used in the elections. It accounted for over 28,000 Tweets of a batch of 100,000. During the week leading up to the elections, AIME collected roughly 800,000 Tweets. Over the course of the elections and the few days following, the total number of collected Tweets jumped to well overÂ 4 million. We sampled just a handful of these tweetsÂ and manually tagged thoseÂ related to violence, rigging and other voting issues using AIME.Â âViolenceâ was described as âthreats, riots, arming, attacks, rumors, lack of security, vandalism, etc.” while âElection Riggingâ was described as âBallot stuffing, issuing invalid ballot papers, voter impersonation, multiple voting, ballot boxes destroyed after counting, bribery, lack of transparency, tampered ballots etc.â Lastly, âVoting Issuesâ was defined asÂ âPolling station logistics issues, technical issues, people unable to vote, media unable to enter, insufficient staff, lack of voter assistance, inadequate voting materials, underage voters, etc.â Any tweet that did not fall into these three categories wasÂ tagged asÂ âOtherâ or âNot Relatedâ. Our Election Classifiers were trained with a total of 571 human-tagged tweets which enabled AIMEÂ to automatically classify well over 1 million tweets (1,263,654 to be precise). The results in the screenshot below show accurate AIME was at auto-classifying tweets based on the different event types defineÂ earlier. AUC is what capturesÂ the “overall accuracy” of AIME’s classifiers.  AIME was ratherÂ good at correctly tagging tweets related to “Voting Issues” (98% accuracy) but drasticallyÂ poor at tagging related to “Election Rigging” (0%). This is not AIME’s fault : ) since it only had 8 examples to learn from. As for “Violence”, the accuracy score was 47%, which is actually surprisingÂ given that AIME only had 14 human-taggedÂ examples to learn from. Lastly,Â AIME did fairly wellÂ atÂ auto-classifying unrelated tweets (accuracy of 86%). Conclusion: this was the first time we tested AIME during an actual election and we’ve learned a lot in the process. The results are not perfect but enough to press on and experiment further with the AIME platform. If you’d like toÂ test AIME yourself (and if you fully recognizeÂ that the tool is experimental and still under development, hence not perfect), then feel free to get in touch with me here. WeÂ have 2 slots open for testing.Â In the meantime, big thanks to my RA Peter for spearheading both this deployment and the subsequent research. 
