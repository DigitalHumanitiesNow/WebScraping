The Economist leads with an editorial and an article on The Dawn of Artificial Intelligence. The editorial starts of with:  âTHE development of full artificial intelligence could spell the end of the human race,â Stephen Hawking warns. Elon Musk fears that the development of artificial intelligence, or AI, may be the biggest existential threat humanity faces. Bill Gates urges people to beware of it. Dread that the abominations people create will become their masters, or their executioners, is hardly new. But voiced by a renowned cosmologist, a Silicon Valley entrepreneur and the founder of Microsoftâhardly Ludditesâand set against the vast investment in AI by big firms like Google and Microsoft, such fears have taken on new weight. With supercomputers in every pocket and robots looking down on every battlefield, just dismissing them as science fiction seems like self-deception. The question is how to worry wisely.  To my knowledge, while the three titans mentioned here of undeniable intellect, it is not clear why two of them are relevant at all. I consider myself reasonably smart, but should I be quoted on my opinion of current treatments of toxoplasmosis? The argument "a smart person says X, therefore we should attend" is known as the appeal to false authority (i.e. a fallacious argument). Such arguments introduce another argumentative crime: the exclusion of actual authority. Eric Horvitz comes to mind:  The head of Microsoftâs main research lab has dismissed fears that artificial intelligence could pose a threat to the survival of the human race. Eric Horvitz believed that humans would not âlose control of certain kinds of intelligencesâ, adding: âIn the end weâll be able to get incredible benefits from machine intelligence in all realms of life, from science to education to economics to daily life.â  The article then stumbles along confusing advances in machine perception and machine learning with intelligence. Predictably, the Kasparov vs Deep Blue achievement is trundled out:  Yet AI is already powerful enough to make a dramatic difference to human life. It can already enhance human endeavour by complementing what people can do. Think of chess, which computers now play better than any person.  Suggesting that any computer can now beat all humans. Deep Blue was a singular machine which was dismantled after the match. And how does chess playing make a dramatic difference to human life? A well informed article - and one that is actually interesting to read - should lead with a concrete set of definitions regarding the components of artificial intelligence (perception, reasoning, etc.) and discuss the discrete advances in those areas. Such an article should discuss the challenges of bringing those things together in anything other than the most rudimentary ways they are combined currently. An interesting article on AI would discuss the economics that drive investments and how they dictate what areas are worked on and which aren't. In all these articles, there is a vague notion of inevitability, as if the machines themselves were selectively investing in research areas, or as if we could stand back and do nothing and this scary version of AI would emerge. It's as if the article were suggesting that landing on the moon was inevitable. The fact that humans did this and then never returned indicates that it was an incredibly intentional endeavor.       
