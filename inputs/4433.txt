 Itâs come to my attention that Fukuzawa Yukichiâs (and othersâ) early Meiji (1868-1912) journal, Meiroku zasshi æå­éèª, is available online not just as PDF (which I knew about) but also as a fully tagged XML corpus from NINJAL (and oh my god, it has lemmas). All right!  I recently met up with Mark Ravina at Association for Asian Studies, who brought this to my attention, and we are doing a lot of brainstorming about what we can do with this as a proof-of-concept project, and then move on to other early Meiji documents. We have big ideas like training OCR to recognize the difference between the katakana and kanji äº, for example; Meiji documents generally break OCR for various reasons like this, because theyâre so different from contemporary Japanese. Itâs like asking Acrobat to handle a medieval manuscript, in some ways. But to start, we want to run the contents of Meiroku zasshi through tools like MALLET and Voyant, just to see how they do with non-Western languages (donât expect any problems, but weâll see) and what we get out of it. Iâd also be interested in going back to the Stanford Core NLP API and seeing what kind of linguistic analysis we can do there. (First, I have to think of a methodology.Â  :O) In order to do this, we need whitespace-delimited text with words separated by spaces. Iâve written about this elsewhere, but to sum up, Japanese is not separated by spaces, so tools intended for Western languages think itâs all one big word. There are currently no easy ways I can find to do this splitting; Iâm currently working on an application that both strips ruby fromÂ Aozora bunko texts AND splits words with a space, but itâs coming slowly. How to get this with Meiroku zasshi in a quick and dirty way that lets us just play with the data? So today after work, Iâm going to use Pythonâs eTree library for XML to take the contents of the word tags from the corpus and just spit them into a text file delimited by spaces. Quick and dirty! Iâve been meaning to do this for weeks, but since itâs a âday of DH,â I thought Iâd use the opportunity to motivate myself. Then, we can play. Exciting stuff, this corpus. Unfortunately most of NINJALâs other amazing corpora are available only on CD-ROMs that work on old versions of Windows. Sigh. But Iâll work with what Iâve got. So thatâs your update from the world of Japanese text analysis. 
