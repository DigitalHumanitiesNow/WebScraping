The BBC has an article about Kalev Leetaru’s project to extract images from millions of Open Library pages. You can read about how it works…  The Internet Archive had used an optical character recognition (OCR) program to analyse each of its 600 million scanned pages in order to convert the image of each word into searchable text.  As part of the process, the software recognised which parts of a page were pictures in order to discard them. Mr Leetaru’s code used this information to go back to the original scans, extract the regions the OCR program had ignored, and then save each one as a separate file in the Jpeg picture format. The software also copied the caption for each image and the text from the paragraphs immediately preceding and following it in the book. Each Jpeg and its associated text was then posted to a new Flickr page, allowing the public to hunt through the vast catalogue using the site’s search tool. “I think one of the greatest things people will do is time travel through the images,” Mr Leetaru said. … or just check out some of the results. Images plus citations plus metadata! We couldn’t be happier. Free to use with no restrictions.         I even found a photo of my house!  Read more details at the Internet Archive’s blog or on Flickr’s “Welcome to the Commons” post.
