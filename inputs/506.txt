Paperphone, user interface beta version Jonathan and I are excited to release our first beta version of Paperphone! Paperphone is a scholarly voice playground. It is a vocal effect processor designed for scholarly papers. Designed to transform the role of the voice in scholarship, the user could apply audio effects (including distortion, reverb, echo, vocoder!, etc) to their voice during live paper presentations. Read about the rationale behind the project. At this point, we are looking for feedback on its usability. We want to know what you think of the user interface and sound design. Does the interface seem intuitive to you? What can we do to improve it? Which of the effects and effect combination are effective, fun, and useful? If you can, please share screenshots of your effect settings (and potential names of your preset configuration). If you have time, please also help us develop its user experience by describing scenarios in which you would use Paperphone: thinking through the kind of prose + effect combination (which configuration of buttons to activate, how would you configure your presets, how would you navigate the controls throughout a paper, etc). We would be grateful if you would provide your feedback in the next couple of days, say, by this Monday March 3. Please email me your feedback at wendy dot f dot hsu at gmail. Paperphone is built in the Max environment. If you don’t already have Max, you can download Max Runtime to run to the patch. Instructions for Paperhpone are included on the app’s interface. If you have Mira, the iPad controller for Max, you could control Paperphone using Mira. There may be bugs in the connection between Mira and Max, however. Download Paperphone (.mxf 20MB, beta1) To download Paperphone, check out this post. Thanks for your support for the project. We are moving right along.
