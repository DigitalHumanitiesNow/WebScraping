
				
		On Several Scales of Reals and Realities, Archival or Digital or Otherwise
		Posted by Roger Whitson on April 18th, 2014
		from The Fold: Leibniz and the Baroque by Gilles Deleuze
The recent issue of J19 dedicated a section to “Evidence and the Archive” without engaging at all with much of the work done in the digital humanities.  This absence is of profound importance to me, because I believe that this kind of lack of collaboration inhibits the critical work humanists can undertake when considering the impact of emerging technologies on cultural experience. Ryan Cordell critiqued the warnings by Maurice Lee and Brian Connolly about the “overabundance” of data as necessarily leading to a lack of critical awareness about the truth by pointing to the many ways the digital humanities have altered their methodologies to address this very point. Ted Underwood, on the other hand, pointed out the lack of any reference to people within Library and Information Science, who study these issues as the major part of their research. [edit: Paul Erickson's piece does engage with library and information science and talks about how librarians might see archives as fundamentally different from literary scholars.] I’d suggest that the inability of most of the authors to mention DH or LIS scholars at all points to a kind of willed ignorance comparable to what Marc Bousquet has recently called the “moral panic” in literary studies.
Normally, panic discourse involves real or perceived threats to a group identified with some aspect of the dominant social order (such as literature faculty members facing the declining cultural capital of their work). Reacting with a disproportionate degree of hostility and resentment, the group generates scapegoats and fake solutions intended to maintain its power and influence in the status quo.
Now Bousquet’s argument has an entirely different context, particularly with regard to jobs and rhetoric and composition, but knee-jerk generalizations against the digital humanities have a similar source: i.e. an anxiety (sometimes justifiable, sometimes not) that work in digital modalities is marginalizing traditional approaches in literary studies. This is not to say that there aren’t good arguments against particular ideologies, methodologies, practices, or funding sources within the digital humanities, but that we need and deserve more care in our critical approaches to technology.

I’d identify Connolly’s piece as particularly problematic in its reactionary stance against the “newfound fascination with an empirical orientation toward evidence.” He offers an alternative vision about evidence by briefly citing Derrida’s work in Archive Fever and Lacan’s notion of The Real as that which is “impossible to be symbolized,” as if no DH scholar has encountered these thinkers before (172-3). One need only look at the work of Matthew Kirschenbaum, whose canonical digital humanities work Mechanisms: New Media and the Forensic Imagination employs Derrida’s sense that “what is no longer archived in the same way is no longer lived in the same way” in Archive Fever to understand the emergence of new (in 2005) technologies like the iPod and TiVo (101).
Connolly’s critique also fails to take into consideration thinkers who have long used Lacan to think about technology. Friedrich Kittler, for instance, quite famously analyzed the technologies of the nineteenth century according to Lacan’s triad in Grammophone, Film, Typewriter (1999). Kittler argues that “only the phonograph can record all the noise produced by the larynx prior to any semiotic order and linguistic meaning. To experience pleasure, Freud’s patients no longer have to desire what philosophers consider good. Rather, they are free to babble. Thus, the real–especially in the talking cure known as psychoanalysis–has the status of phonography” (16). So, for Kittler, a scholar who forced his students to take “Mathematics for Media Studies” before studying with him, the Real isn’t the product of some misty imaginative revelry, it’s a material and technological reality that can be recorded and sometimes experienced but not signified or counted. Computers are quite powerful ways to study the Real because they sit before us as alien black boxes with magical powers, infused with voltaic energies and obscured circuits, communicating with us by obscuring themselves. It is only when those powers glitch and fail that we start to experience the guts of their material mechanisms (to refer back to Kirschenbaum).
But babbling, glitches, and stray marks are also often analyzed in the digital humanities. Trevor Owens has spent quite a bit of time using circuit-bending to illustrate non-intentional uses of computational machines. Jerome McGann has long advocated a notion of deformance when conducting digital analysis, which he defines in the context of photoshop as “breaking down the rhetorical authority of the ‘finished’ picture and allowing certain of its concealed features to emerge” (25). This approach is central to many practitioners of what Connolly derogatorily calls “surface” reading. Stephen Ramsay works through deformance in his practice of algorithmic criticism as “an explicit technological program for critical reading” (38). Mark Sample advocates a more general deformed humanities in which scholars “take apart the world, deform it, make something new.” And the scores of twitter bots, electronic literature, and hacked electronics attest to this vision of the broken, glitched, unintentional beauty of DH’s attempted-encounters with different material reals.  Of course, Brian Connolly’s invocation of “surface” as a derogatory term doesn’t even engage with the more explicit rejection of such a paradigm by celebrated theorists like Gilles Deleuze, for whom there is no real depth or interior, but everything is a surface or exterior folded in on itself. Interiors or depths are “like the invagination of another tissue in embryology, or the operation of a lining of a garment: twisting, folding over, stopping” (98)
As Derrida, Lacan, and Deleuze would remind us – we need to push the boundaries of our thought. Computation can help us do that. Ted Underwood suggests “[p]erhaps the point of distant reading isn’t that a larger collection will necessarily be ‘more representative,’ but that it allows you to compare a wider range of different kinds of representativeness.” Distance helps us to discover new surfaces for our thought. It’s not naive empiricism, but a sort of speculative empiricism that uncovers the strangeness in things we never even considered to consider.
Share this:
				
